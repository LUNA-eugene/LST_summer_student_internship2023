{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic infobox\n",
    "จากครั้งที่แล้วที่เราได้มีการสร้างฟังก์ชันที่สามารถสร้าง infobox และสกัดค่า value ตาม key ที่เราต้องการได้ เราจะสังเกตได้ว่ามีบางที่มีแพทเทิร์นการกาค่า value ลักษณะเดียวกันหรือเหมือนกัน เช่นการหาที่ตั้ง , การหาประเภท เป็นต้น ในครั้งนี้เราจึงเขียนเป็นฟังก์ชันให้สามารถเรียกใช้ซ้ำกันได้ เพื่อลดปริมาณการเขียนโค้ด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# วัด\n",
    "syn_วัด = {'location': ['ที่ตั้ง', 'ตั้งอยู่', 'ที่อยู่'],\n",
    "'type': ['ประเภท', 'เป็น'],\n",
    "'sect': ['นิกาย', 'ฝ่าย', 'สังกัด', 'ในสังกัด']}\n",
    "\n",
    "# วัง\n",
    "syn_วัง = {'type': ['ประเภท', 'เป็น'],\n",
    "'location': ['ที่ตั้ง' ,'ที่อยู่',  'ตั้งอยู่' ],\n",
    "'status': ['สถานะ'],\n",
    "'city': ['เมือง', 'จังหวัด'],\n",
    "'country': ['ประเทศ'],\n",
    "'start building': ['เริ่มสร้าง', 'ก่อตั้ง', 'สร้าง' ,'สร้างเมื่อ', 'สร้างขึ้นเมื่อ']}\n",
    "\n",
    "# อุทยานแห่งชาติ\n",
    "syn_อุทยานแห่งชาติ = {'location': ['ที่ตั้ง','ที่อยู่' , 'ตั้งอยู่', 'ตั้งอยู่ที่' , 'ตั้งอยู่ใน'],\n",
    "'area': ['พื้นที่', 'ขนาด', 'เนื้อที่'],\n",
    "'government agency': ['หน่วยราชการ', 'กรม'],\n",
    "'establish': ['จัดตั้ง', 'จัดตั้งเป็นอุทยานแห่งชาติเมื่อ'],\n",
    "'coordinates': ['พิกัด', 'พิกัดทางภูมิศาสตร์']}\n",
    "\n",
    "# สถาบันอุดมศึกษา\n",
    "syn_สถาบันอุดมศึกษา = {'type': ['ประเภท', 'เป็น'],\n",
    "'website': ['เว็บไซต์', 'website', 'เว็บ'],\n",
    "'location': ['ที่ตั้ง', 'ที่อยู่' ,  'ตั้งอยู่'],\n",
    "'initials': ['ชื่อย่อ', 'อักษรย่อ'],\n",
    "'establish': ['สถาปนา', 'เมื่อ', 'ก่อตั้งขึ้นเมื่อ', 'ก่อตั้งขึ้นเมื่อวันที่']}\n",
    "\n",
    "# โรงพยาบาล\n",
    "syn_โรงพยาบาล = {'location': ['ที่ตั้ง', 'ที่อยู่' ,  'ตั้งอยู่'],\n",
    "'type': ['ประเภท', 'เป็น'],\n",
    "'number of beds': ['จำนวนเตียง', 'ขนาด', 'จำนวน'],\n",
    "'website': ['เว็บไซต์'],\n",
    "'affiliation': ['สังกัด']}\n",
    "\n",
    "# default\n",
    "syn_default = {'location': ['ที่ตั้ง', 'ที่อยู่' ,  'ตั้งอยู่'],\n",
    "            'name': ['ชื่อ', 'เป็น'],\n",
    "            'type': ['ประเภท', 'เป็น'],\n",
    "            'Related person': ['บุคคลที่เกี่ยวข้อง']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_infobox_place(data, format_json):\n",
    "    from pythainlp.util import normalize\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    def postag_ner(data):\n",
    "        from pythainlp.tag import pos_tag\n",
    "        from pythainlp.tokenize import word_tokenize\n",
    "        from pythainlp.tag import NER\n",
    "\n",
    "        ner = NER(\"thainer\")\n",
    "        data_ner = ner.tag(data)\n",
    "\n",
    "        data_ner_modified = [list(tup) for tup in data_ner]\n",
    "        words = []\n",
    "        for word in data_ner_modified:\n",
    "            words.append(word[0])\n",
    "\n",
    "        data_pos_modified = [list(tup) for tup in pos_tag(words)]\n",
    "\n",
    "        merged_list = [data_ner_modified[i] + data_pos_modified[i] for i in range(len(data_ner_modified))]\n",
    "        data_ner_pos =  [sublist[:2] + sublist[3:] for sublist in merged_list]\n",
    "        data_ner_pos = [item for item in data_ner_pos if item != [' ', 'O', 'PUNC']]\n",
    "        return(data_ner_pos)\n",
    "\n",
    "    def extract_location(data_ner_pos, syn_data, type):\n",
    "        import re\n",
    "        value_location = ''\n",
    "        for i in range(len(data_ner_pos)):\n",
    "            if data_ner_pos['Word'][i] in syn_data[type]:\n",
    "                for x in range(i + 1, i + 5):\n",
    "                    if re.search(r'-L', data_ner_pos['NER'][x]):\n",
    "                        for j in range(i + 1, i + 15):\n",
    "                            #if data_ner_pos['POS tags'][j] in ['RPRE', 'JCRG']:\n",
    "                                #value_location += data_ner_pos['Word'][j]\n",
    "                            if data_ner_pos['NER'][j] == 'B-LOCATION':\n",
    "                                value_location += ' ' + data_ner_pos['Word'][j] \n",
    "                            elif data_ner_pos['NER'][j] == 'I-LOCATION':\n",
    "                                value_location += data_ner_pos['Word'][j] \n",
    "                            elif re.search(r'-ZIP', data_ner_pos['NER'][j]):\n",
    "                                value_location += data_ner_pos['Word'][j] + ' '\n",
    "\n",
    "                            # จังหวัด\n",
    "                            elif data_ner_pos['Word'][j] == 'จังหวัด' and data_ner_pos['NER'][j] == 'O':\n",
    "                                value_location += ' ' + data_ner_pos['Word'][j] \n",
    "                                value_location += data_ner_pos['Word'][j+1] \n",
    "                            # เลขที่\n",
    "                            elif data_ner_pos['Word'][j] == 'เลขที่':\n",
    "                                value_location += data_ner_pos['Word'][j] + ' '\n",
    "                                if data_ner_pos['POS tags'][j+1] == 'DCNM':\n",
    "                                    value_location += data_ner_pos['Word'][j+1] + ' ' \n",
    "                            # รหัสไปรษณีย์\n",
    "                            elif data_ner_pos['POS tags'][j] == 'DCNM' and len(data_ner_pos['Word'][j])== 5:\n",
    "                                value_location += data_ner_pos['Word'][j]\n",
    "                        value_location += ','  \n",
    "                        break\n",
    "        \n",
    "                    elif data_ner_pos['POS tags'][x] == 'VACT' and data_ner_pos['POS tags'][x+1] == 'NCMN':\n",
    "                        value_location += data_ner_pos['Word'][x]\n",
    "                        value_location += data_ner_pos['Word'][x+1]\n",
    "                #break\n",
    "                        \n",
    "        return value_location\n",
    "\n",
    "    def find_value_nextword(df, syn_data, type, word):\n",
    "        value = ''\n",
    "        import re\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_data[type]:\n",
    "                value += df['Word'][i]\n",
    "                for j in range(i + 1, i + 3):\n",
    "                    value += df['Word'][j] + ' '\n",
    "                    if re.search(word, df['Word'][j+1]):\n",
    "                        value += df['Word'][j+1]\n",
    "                    break\n",
    "        return value\n",
    "\n",
    "    def find_value_nextword_search(df, syn_data, type, word):\n",
    "        value = ''\n",
    "        import re\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_data[type]:\n",
    "                for j in range(i+1, i+17):\n",
    "                    if re.search(word, df['NER'][j]):\n",
    "                        value += df['Word'][j]\n",
    "                break\n",
    "                    \n",
    "        return value      \n",
    "\n",
    "    def find_type(data_ner_pos, syn_data, type, word_list):\n",
    "        value = ''\n",
    "        for i in range(len(data_ner_pos)):\n",
    "            if data_ner_pos['Word'][i] in syn_data[type]:\n",
    "                for x in range(i + 1, i + 2):\n",
    "                    if data_ner_pos['Word'][x] in word_list:\n",
    "                        value += data_ner_pos['Word'][x] \n",
    "                    elif data_ner_pos['POS tags'][x] in ['NCMN', 'RPRE']:\n",
    "                        value += data_ner_pos['Word'][x] \n",
    "                break\n",
    "                    \n",
    "        return value   \n",
    "        \n",
    "    def find_date(df, syn_data, type):\n",
    "        import re\n",
    "        value = ''\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_data[type]:\n",
    "                for j in range(i+1 ,i+10):\n",
    "                    if df['POS tags'][j] == 'NCMN' and df['POS tags'][j+1] == 'NCNM':\n",
    "                        value += df['Word'][j]\n",
    "                        value += df['Word'][j+1]\n",
    "                    elif re.search(r'-DATE', df['NER'][j]):\n",
    "                        value += df['Word'][j]\n",
    "                break\n",
    "        return value    \n",
    "\n",
    "    def find_website(df, syn_data, type):\n",
    "        import re\n",
    "        value = ''\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_data[type]:\n",
    "                    for j in range(i+1, i+10):\n",
    "                        if re.search(r'-URL', df['NER'][j]):\n",
    "                            value += df['Word'][j]\n",
    "                    break\n",
    "        return value     \n",
    "        \n",
    "    def find_quantity(df, syn_data ,type):\n",
    "        import re\n",
    "        value = ''\n",
    "        for i in range(len(df)):\n",
    "                if df['Word'][i] in syn_data[type]:\n",
    "                    for j in range(i+1, i+10):\n",
    "                        if df['POS tags'][j] in ['DIBQ', 'DIAQ', 'DCNM', 'CMTR', 'JCMP', 'CNIT']:\n",
    "                            value += df['Word'][j] + ' '\n",
    "\n",
    "                        elif df['Word'][j] == 'หรือ'or df['POS tags'][j] == 'PUNC':\n",
    "                            value+= df['Word'][j] + ' '\n",
    "\n",
    "                        elif re.search(r'-MONEY' , df['NER'][j]):\n",
    "                            value +=df['Word'][j] + ' '\n",
    "                    break\n",
    "                \n",
    "        return value\n",
    "\n",
    "    def find_type_temple(df):\n",
    "        value_type = ''\n",
    "        # type\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_วัด['type']:\n",
    "                for j in range(i + 1, i + 10):\n",
    "                    if df['Word'][j] == 'วัด' :\n",
    "                        value_type += df['Word'][j]\n",
    "                        if df['Word'][j+1] == 'ไทย' :\n",
    "                            value_type += df['Word'][j+1]\n",
    "                        \n",
    "\n",
    "                    elif df['Word'][j] in ['พระอารามหลวง', 'วัดราษฎร์','วัดหลวง']:\n",
    "                        value_type += df['Word'][j] + ' '\n",
    "                        if df['Word'][j + 1] in ['ชั้นเอก', 'ชั้นโท', 'ชั้นตรี']:\n",
    "                            value_type += df['Word'][j + 1] + ' '\n",
    "                            if df['Word'][j+2] == 'ชนิด':\n",
    "                                value_type += df['Word'][j+2]\n",
    "                                if df['Word'][j + 3] in ['ราชวรมหาวิหาร', 'ราชวรวิหาร', 'วรมหาวิหาร', 'วรวิหาร', 'สามัญ']:\n",
    "                                    value_type += df['Word'][j + 3] + ' '\n",
    "                break\n",
    "\n",
    "        return value_type\n",
    "\n",
    "    def find_status_palace(df):\n",
    "        import re\n",
    "        value_status = ''\n",
    "        # status\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_วัง['status']:\n",
    "                for j in range(i+1, i+3):\n",
    "                    if re.search(r'^N', df['POS tags'][j]):\n",
    "                        value_status += df['Word'][j]\n",
    "                    elif df['POS tags'][j] == 'RPRE' and re.search(r'^N', df['POS tags'][j+1]):\n",
    "                        value_status += df['Word'][j]\n",
    "                    elif df['POS tags'][j] != 'VSTA':\n",
    "                        value_status += df['Word'][j]\n",
    "                break\n",
    "            \n",
    "        return value_status\n",
    "    \n",
    "    data = normalize(data)\n",
    "    data_ner_pos = postag_ner(data)\n",
    "    df = pd.DataFrame(data_ner_pos, columns=['Word', 'NER', 'POS tags'])\n",
    "    infobox = {}\n",
    "\n",
    "\n",
    "    # วัด\n",
    "    if re.search(r'เป็นวัด|เป็นพระอารามหลวง', data) or df['Word'][0] in ['วัด']:\n",
    "        value_location = extract_location(df, syn_data=syn_วัด, type='location')\n",
    "        value_type = find_type_temple(df)\n",
    "        value_sect = find_value_nextword(df, syn_data=syn_วัด, type='sect', word='นิกาย')\n",
    "\n",
    "        infobox[syn_วัง['type'][0]] = value_type\n",
    "        infobox[syn_วัด['location'][0]] = value_location\n",
    "        infobox[syn_วัด['sect'][0]] = value_sect\n",
    "        \n",
    "\n",
    "    # พระราชวัง\n",
    "    elif re.search(r'เป็นวัง|เป็นพระราชวัง', data) or df['Word'][0] in ['วัง', 'พระราชวัง']:\n",
    "        value_type = find_type(data_ner_pos = df, syn_data =syn_วัง , type='type', word_list=['วัง','พระราชวัง'])\n",
    "        value_location = extract_location(df, syn_data=syn_วัง, type='location')\n",
    "        value_status = find_status_palace(df)\n",
    "        value_city = find_value_nextword(df, syn_data=syn_วัง, type='city', word='จังหวัด')\n",
    "        value_country = find_value_nextword(df, syn_data=syn_วัง, type='country', word='ประเทศ')\n",
    "        value_start_building = find_date(df, syn_data=syn_วัง, type='start building')\n",
    "        \n",
    "        infobox[syn_วัง['type'][0]] = value_type\n",
    "        infobox[syn_วัง['location'][0]] = value_location\n",
    "        infobox[syn_วัง['status'][0]] = value_status\n",
    "        infobox[syn_วัง['city'][0]] = value_city\n",
    "        infobox[syn_วัง['country'][0]] = value_country\n",
    "        infobox[syn_วัง['start building'][0]] = value_start_building\n",
    "    \n",
    "    # อุทยานแห่งชาติ\n",
    "    elif re.search(r'เป็นอุทยานแห่งชาติ', data) or df['Word'][0] in ['อุทยานแห่งชาติ'] :\n",
    "        value_location = extract_location(df, syn_data=syn_อุทยานแห่งชาติ, type='location')\n",
    "        value_area = find_quantity(df, syn_อุทยานแห่งชาติ, type='area')\n",
    "        value_government_agency = find_value_nextword_search(df, syn_data=syn_อุทยานแห่งชาติ, type='government agency', word='-ORGANIZATION')\n",
    "        value_establish = find_date(df, syn_data=syn_อุทยานแห่งชาติ, type='establish')\n",
    "        value_coordinates = find_value_nextword_search(df, syn_data=syn_อุทยานแห่งชาติ, type='coordinates', word='-LAW')\n",
    "                                \n",
    "        infobox[syn_อุทยานแห่งชาติ['location'][0]] = value_location\n",
    "        infobox[syn_อุทยานแห่งชาติ['area'][0]] = value_area\n",
    "        infobox[syn_อุทยานแห่งชาติ['government agency'][0]] = value_government_agency\n",
    "        infobox[syn_อุทยานแห่งชาติ['establish'][0]] = value_establish\n",
    "        infobox[syn_อุทยานแห่งชาติ['coordinates'][0]] = value_coordinates\n",
    "\n",
    "    # สถาบันอุดมศึกษา\n",
    "    elif re.search(r'เป็นมหาวิทยาลัย|เป็นสถาบันอุดมศึกษา|ระดับอุดมศึกษา', data) or df['Word'][0] in ['มหาวิทยาลัย', 'วิทยาลัย', 'สถาบันการอาชีวศึกษา']:\n",
    "        \n",
    "        value_type = find_type(data_ner_pos = df, syn_data = syn_สถาบันอุดมศึกษา, type = 'type', word_list = ['มหาวิทยาลัย', 'สถาบัน'])\n",
    "        value_website = find_website(df, syn_data=syn_สถาบันอุดมศึกษา, type='website')\n",
    "        value_location = extract_location(df, syn_data=syn_สถาบันอุดมศึกษา, type='location')\n",
    "        value_initials = find_value_nextword_search(df, syn_data = syn_สถาบันอุดมศึกษา, type = 'initials', word = '-ORGANIZATION')\n",
    "        value_establish = find_date(df, syn_data=syn_สถาบันอุดมศึกษา, type='establish')\n",
    "\n",
    "        infobox[syn_สถาบันอุดมศึกษา['type'][0]] = value_type\n",
    "        infobox[syn_สถาบันอุดมศึกษา['location'][0]] = value_location\n",
    "        infobox[syn_สถาบันอุดมศึกษา['website'][0]] = value_website\n",
    "        infobox[syn_สถาบันอุดมศึกษา['initials'][0]] = value_initials\n",
    "        infobox[syn_สถาบันอุดมศึกษา['establish'][0]] = value_establish\n",
    "\n",
    "    # โรงพยาบาล\n",
    "    elif re.search(r'เป็นสถาบันการแพทย์|เป็นโรงพยาบาล', data) or df['Word'][0] in ['โรงพยาบาล', 'ศูนย์การแพทย์'] :\n",
    "        value_location = extract_location(df, syn_data=syn_โรงพยาบาล, type='location')\n",
    "        value_type = find_type(data_ner_pos = df, syn_data = syn_โรงพยาบาล, type = 'type', word_list = ['โรงพยาบาล', 'สถาบัน'])\n",
    "        value_number_beds = find_quantity(df, syn_data=syn_โรงพยาบาล ,type='number of beds')\n",
    "        value_website = find_website(df, syn_data=syn_โรงพยาบาล, type='website')\n",
    "        value_affiliation = find_value_nextword_search(df, syn_data = syn_โรงพยาบาล, type = 'affiliation', word = '-ORGANIZATION')\n",
    "\n",
    "        \n",
    "        infobox[syn_โรงพยาบาล['type'][0]] = value_type  \n",
    "        infobox[syn_โรงพยาบาล['location'][0]] = value_location     \n",
    "        infobox[syn_โรงพยาบาล['number of beds'][0]] = value_number_beds\n",
    "        infobox[syn_โรงพยาบาล['website'][0]] = value_website\n",
    "        infobox[syn_โรงพยาบาล['affiliation'][0]] = value_affiliation\n",
    "\n",
    "    # default\n",
    "    else:\n",
    "        value_location = extract_location(df, syn_data=syn_default,type='location')\n",
    "        value_type = ''\n",
    "        value_name = ''\n",
    "        value_Related_person = ''\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            # name and type\n",
    "            if df['Word'][i] in syn_default['name']:\n",
    "                if df['Word'][i] == 'เป็น':\n",
    "                    # ชื่อ\n",
    "                    for j in range(0, i):\n",
    "                        if re.search(r'^N', df['POS tags'][j]):\n",
    "                            value_name = df['Word'][j] + ' '\n",
    "                            break\n",
    "                    for j in range(i, i+2):\n",
    "                        if re.search(r'^N', df['POS tags'][j]):\n",
    "                            value_type = df['Word'][j] + ' '\n",
    "                            break\n",
    "                    break\n",
    "\n",
    "            #value_Related_person\n",
    "            else :\n",
    "                if re.search(r'-PERSON',df['NER'][i]):\n",
    "                    value_Related_person += df['Word'][i]\n",
    "\n",
    "        infobox[syn_default['name'][0]] = value_name\n",
    "        infobox[syn_default['type'][0]] = value_type\n",
    "        infobox[syn_default['location'][0]] = value_location\n",
    "        infobox[syn_default['Related person'][0]] = value_Related_person\n",
    "    \n",
    "    if format_json == True:\n",
    "        return infobox\n",
    "    else:\n",
    "        format_infobox = '{{Infobox\\n'\n",
    "        for key, value in infobox.items():\n",
    "            if value != '':\n",
    "                format_infobox += '| {} = {}\\n'.format(key, value)\n",
    "        format_infobox += '}}'\n",
    "        return format_infobox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template_infobox_place(data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic infobox with google sheet\n",
    "โค้ดในการสร้าง Infobox อัตโนมัติโดยผู้ใช้สามารถปรับเปลี่ยนฟังก์ชันในการหา value ผ่านทาง google sheet ได้ \n",
    "Link google sheet : https://docs.google.com/spreadsheets/d/1DGtkzyobGgcDD59man_nGt4rHOSsl8_ZiYg8_PDSDFw/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_infobox_place(data, name_rule_temple = 'isTemple01' , name_rule_palace = 'isPalace01', name_rule_nationalpark = 'isNationalPark01', \n",
    "                           name_rule_university = 'isUniversity01', name_rule_hospital = 'isHospital01', name_rule_default = 'isDefault01'):\n",
    "                           \n",
    "    from pythainlp.util import normalize\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    import ast\n",
    "\n",
    "\n",
    "    def postag_ner(data):\n",
    "        from pythainlp.tag import pos_tag\n",
    "        from pythainlp.tokenize import word_tokenize\n",
    "        from pythainlp.tag import NER\n",
    "\n",
    "        ner = NER(\"thainer\")\n",
    "        data_ner = ner.tag(data)\n",
    "\n",
    "        data_ner_modified = [list(tup) for tup in data_ner]\n",
    "        words = []\n",
    "        for word in data_ner_modified:\n",
    "            words.append(word[0])\n",
    "\n",
    "        data_pos_modified = [list(tup) for tup in pos_tag(words)]\n",
    "\n",
    "        merged_list = [data_ner_modified[i] + data_pos_modified[i] for i in range(len(data_ner_modified))]\n",
    "        data_ner_pos =  [sublist[:2] + sublist[3:] for sublist in merged_list]\n",
    "        data_ner_pos = [item for item in data_ner_pos if item != [' ', 'O', 'PUNC']]\n",
    "        return(data_ner_pos)\n",
    "\n",
    "    def extract_location(data_ner_pos, syn_words = ['ที่ตั้ง', 'ตั้งอยู่', 'ที่อยู่'] , wordNERsearch = 'L', wordNER_B = 'B-LOCATION', wordNER_I = 'I_LOCATION', \n",
    "                     wordNERsearch_1_2 = '-ZIP', wordis = 'จังหวัด', wordNERis = 'O', wordis_1_2 = 'เลขที่', nextwordPOS = 'DCNM',\n",
    "                     wordPOSis = 'DCNM',wordPOSis_2 = 'VACT', nextwordPOS_2 = 'NCMN'):\n",
    "    \n",
    "        value_location = ''\n",
    "        for i in range(len(data_ner_pos)):\n",
    "            if data_ner_pos['Word'][i] in syn_words:\n",
    "                for x in range(i + 1, i + 5):\n",
    "                    if re.search(wordNERsearch , data_ner_pos['NER'][x]):\n",
    "                        for j in range(i + 1, i + 15):\n",
    "                            #if data_ner_pos['POS tags'][j] in ['RPRE', 'JCRG']:\n",
    "                                #value_location += data_ner_pos['Word'][j]\n",
    "                            if data_ner_pos['NER'][j] == wordNER_B:\n",
    "                                value_location += ' ' + data_ner_pos['Word'][j] \n",
    "                            elif data_ner_pos['NER'][j] == wordNER_I:\n",
    "                                value_location += data_ner_pos['Word'][j] \n",
    "                            elif re.search(wordNERsearch_1_2, data_ner_pos['NER'][j]):\n",
    "                                value_location += data_ner_pos['Word'][j] + ' '\n",
    "\n",
    "                            # จังหวัด\n",
    "                            elif data_ner_pos['Word'][j] == wordis and data_ner_pos['NER'][j] == wordNERis:\n",
    "                                value_location += ' ' + data_ner_pos['Word'][j] \n",
    "                                value_location += data_ner_pos['Word'][j+1] \n",
    "                            # เลขที่\n",
    "                            elif data_ner_pos['Word'][j] == wordis_1_2:\n",
    "                                value_location += data_ner_pos['Word'][j] + ' '\n",
    "                                if data_ner_pos['POS tags'][j+1] == nextwordPOS:\n",
    "                                    value_location += data_ner_pos['Word'][j+1] + ' ' \n",
    "                            # รหัสไปรษณีย์\n",
    "                            elif data_ner_pos['POS tags'][j] == wordPOSis and len(data_ner_pos['Word'][j])== 5:\n",
    "                                value_location += data_ner_pos['Word'][j]\n",
    "                        value_location += ','  \n",
    "                        break\n",
    "        \n",
    "                    elif data_ner_pos['POS tags'][x] == wordPOSis_2 and data_ner_pos['POS tags'][x+1] == nextwordPOS_2 :\n",
    "                        value_location += data_ner_pos['Word'][x]\n",
    "                        value_location += data_ner_pos['Word'][x+1]\n",
    "                #break\n",
    "                        \n",
    "        return value_location\n",
    "\n",
    "    def find_value_nextword(df, word, syn_words = ['ประเภท', 'เป็น'] ):\n",
    "        value = ''\n",
    "        import re\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_words:\n",
    "                value += df['Word'][i]\n",
    "                for j in range(i + 1, i + 3):\n",
    "                    value += df['Word'][j] + ' '\n",
    "                    if re.search(word, df['Word'][j+1]):\n",
    "                        value += df['Word'][j+1]\n",
    "                    break\n",
    "        return value\n",
    "\n",
    "    def find_value_nextword_search(df, syn_words, wordNER):\n",
    "        value = ''\n",
    "        import re\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_words:\n",
    "                for j in range(i+1, i+17):\n",
    "                    if re.search(wordNER, df['NER'][j]):\n",
    "                        value += df['Word'][j]\n",
    "                break\n",
    "                    \n",
    "        return value      \n",
    "\n",
    "\n",
    "    def find_date(df, syn_words, wordsPOS, nextwordsPOS, wordsNER):\n",
    "        import re\n",
    "        value = ''\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_words:\n",
    "                for j in range(i+1 ,i+10):\n",
    "                    if df['POS tags'][j] == wordsPOS and df['POS tags'][j+1] == nextwordsPOS:\n",
    "                        value += df['Word'][j]\n",
    "                        value += df['Word'][j+1]\n",
    "                    elif re.search(wordsNER, df['NER'][j]):\n",
    "                        value += df['Word'][j]\n",
    "                break\n",
    "        return value\n",
    "\n",
    "    def find_website(df, syn_words, wordsNER ):\n",
    "        import re\n",
    "        value = ''\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_words:\n",
    "                    for j in range(i+1, i+10):\n",
    "                        if re.search(wordsNER, df['NER'][j]):\n",
    "                            value += df['Word'][j]\n",
    "                    break\n",
    "        return value\n",
    "\n",
    "    def find_type_temple(df, syn_words = ['ประเภท', 'เป็น'] , words = 'วัด', nextword = 'ไทย', \n",
    "                        setofword_2_1 =['พระอารามหลวง', 'วัดราษฎร์','วัดหลวง'] , setofword_2_2 = ['ชั้นเอก', 'ชั้นโท', 'ชั้นตรี']\n",
    "                        , words_2 = 'ชนิด' , setofword_2_3 = ['ราชวรมหาวิหาร', 'ราชวรวิหาร', 'วรมหาวิหาร', 'วรวิหาร', 'สามัญ']):\n",
    "        value_type = ''\n",
    "        # type\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_words:\n",
    "                for j in range(i + 1, i + 10):\n",
    "                    if df['Word'][j] == words :\n",
    "                        value_type += df['Word'][j]\n",
    "                        if df['Word'][j+1] == nextword :\n",
    "                            value_type += df['Word'][j+1]\n",
    "                        \n",
    "\n",
    "                    elif df['Word'][j] in setofword_2_1:\n",
    "                        value_type += df['Word'][j] + ' '\n",
    "                        if df['Word'][j + 1] in setofword_2_2:\n",
    "                            value_type += df['Word'][j + 1] + ' '\n",
    "                            if df['Word'][j+2] == words_2:\n",
    "                                value_type += df['Word'][j+2]\n",
    "                                if df['Word'][j + 3] in setofword_2_3:\n",
    "                                    value_type += df['Word'][j + 3] + ' '\n",
    "                break\n",
    "\n",
    "        return value_type\n",
    "\n",
    "    def find_type(data_ner_pos, syn_words,  word_list,  POS_list = ['NCMN', 'RPRE']):\n",
    "        value = ''\n",
    "        for i in range(len(data_ner_pos)):\n",
    "            if data_ner_pos['Word'][i] in syn_words:\n",
    "                for x in range(i + 1, i + 2):\n",
    "                    if data_ner_pos['Word'][x] in word_list:\n",
    "                        value += data_ner_pos['Word'][x] \n",
    "                    elif data_ner_pos['POS tags'][x] in POS_list:\n",
    "                        value += data_ner_pos['Word'][x] \n",
    "                break\n",
    "                    \n",
    "        return value\n",
    "\n",
    "    def find_status_palace(df, syn_words, wordsPOS, wordsPOS_2, nextwordsPOS, isnotwords):\n",
    "        import re\n",
    "        value_status = ''\n",
    "        # status\n",
    "        for i in range(len(df)):\n",
    "            if df['Word'][i] in syn_words:\n",
    "                for j in range(i+1, i+3):\n",
    "                    if re.search(wordsPOS, df['POS tags'][j]):\n",
    "                        value_status += df['Word'][j]\n",
    "                    elif df['POS tags'][j] == wordsPOS_2 and re.search(nextwordsPOS, df['POS tags'][j+1]):\n",
    "                        value_status += df['Word'][j]\n",
    "                    elif df['POS tags'][j] != isnotwords:\n",
    "                        value_status += df['Word'][j]\n",
    "                break\n",
    "            \n",
    "        return value_status\n",
    "\n",
    "    def find_quantity(df, syn_words, POS_list , iswords , POSwords, NERwords):\n",
    "        import re\n",
    "        value = ''\n",
    "        for i in range(len(df)):\n",
    "                if df['Word'][i] in syn_words:\n",
    "                    for j in range(i+1, i+10):\n",
    "                        if df['POS tags'][j] in POS_list :\n",
    "                            value += df['Word'][j] + ' '\n",
    "\n",
    "                        elif df['Word'][j] == iswords or df['POS tags'][j] == POSwords:\n",
    "                            value+= df['Word'][j] + ' '\n",
    "\n",
    "                        elif re.search(NERwords , df['NER'][j]):\n",
    "                            value +=df['Word'][j] + ' '\n",
    "                    break\n",
    "                \n",
    "        return value\n",
    "\n",
    "    def read_googlesheet(SHEETNAME):\n",
    "        SHEET_ID = '1DGtkzyobGgcDD59man_nGt4rHOSsl8_ZiYg8_PDSDFw'\n",
    "        SHEET_NAME = SHEETNAME\n",
    "        url = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "        rule = pd.read_csv(url)\n",
    "        return(rule)\n",
    "\n",
    "    def select_rule(name_rule, rule):\n",
    "        rule = rule[rule['Rule'] == name_rule]\n",
    "        rule_dict = rule.to_dict('records')\n",
    "        dict = {}\n",
    "        for item in rule_dict:\n",
    "            for key, value in item.items():\n",
    "                dict[key] = value\n",
    "        return dict\n",
    "\n",
    "\n",
    "    data = normalize(data)\n",
    "    data_ner_pos = postag_ner(data)\n",
    "    df = pd.DataFrame(data_ner_pos, columns=['Word', 'NER', 'POS tags'])\n",
    "    infobox = {}\n",
    "\n",
    "    if re.search(r'เป็นวัด|เป็นพระอารามหลวง', data) or df['Word'][0] in ['วัด']:\n",
    "        # วัด\n",
    "        rule = read_googlesheet('rule_Temple')\n",
    "        dict = select_rule(name_rule_temple, rule = rule)\n",
    "        \n",
    "        value_location = extract_location(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF02']), dict['filterNextWord_inSynPOS_search_IF02_1'], dict['filterNextWord_inSynNER_isBeginTag_IF02_1_1'],\n",
    "                                          dict['filterNextWord_inSynNER_isInsideTag_IF02_1_2'], dict['filterNextWord_inSynNER_search_IF02_1_3'],dict['filterNextWord_inSynWord_is_IF02_1_4'], \n",
    "                                            dict['filterNextWord_inSynNER_is_IF02_1_4'], dict['filterNextWord_inSynWord_is_IF02_1_5'], dict['filterNextWord_inSynPOS_nextis_IF02_1_5'],\n",
    "                                            dict['filterNextWord_inSynPOS_is_IF02_1_6'])\n",
    "        value_type = find_type_temple(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF01']), dict['filterNextWord_inSynWord_is_IF01_1'], dict['filterNextWord_inSynWord_nextwordis_IF01_1'],\n",
    "                                      ast.literal_eval(dict['filterNextWord_inSynWord_secondwordisin_IF01_2']),dict['filterNextWord_inSynWord_thirdwordis_IF01_2'],\n",
    "                                      ast.literal_eval(dict['filterNextWord_inSynWord_fourthwordisin_IF01_2'])) \n",
    "        value_sect = find_value_nextword(df, dict['filterNextWord_inSynPOS_search_IF03'], syn_words = ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF03']))\n",
    "\n",
    "        infobox[syn_วัง['type'][0]] = value_type\n",
    "        infobox[syn_วัด['location'][0]] = value_location\n",
    "        infobox[syn_วัด['sect'][0]] = value_sect\n",
    "    \n",
    "    # พระราชวัง\n",
    "    elif re.search(r'เป็นวัง|เป็นพระราชวัง', data) or df['Word'][0] in ['วัง', 'พระราชวัง']:\n",
    "        rule = read_googlesheet('rule_Palace')\n",
    "        dict = select_rule(name_rule_palace, rule = rule)\n",
    "        \n",
    "        value_type = find_type(df, ast.literal_eval(dict['filterNextWord_inSynWord_is_IF01_1']),ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF01']),ast.literal_eval(dict['filterNextWord_inSynPOS_in_IF01_2']))\n",
    "        value_location = extract_location(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF02']), dict['filterNextWord_inSynPOS_search_IF02_1'], dict['filterNextWord_inSynNER_isBeginTag_IF02_1_1'],\n",
    "                                          dict['filterNextWord_inSynNER_isInsideTag_IF02_1_2'], dict['filterNextWord_inSynNER_search_IF02_1_3'],dict['filterNextWord_inSynWord_is_IF02_1_4'], \n",
    "                                            dict['filterNextWord_inSynNER_is_IF02_1_4'], dict['filterNextWord_inSynWord_is_IF02_1_5'], dict['filterNextWord_inSynPOS_nextis_IF02_1_5'],\n",
    "                                            dict['filterNextWord_inSynPOS_is_IF02_1_6'])\n",
    "        value_status = find_status_palace(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF03']),dict['filterNextWord_inSynPOS_search_IF03_1'], \n",
    "                           dict['filterNextWord_inSynPOS_is_IF03_2'], dict['filterNextWord_inSynPOS_nextPOSsearchis_IF03_2'], dict['filterNextWord_inSynPOS_isnot_IF03_3'])\n",
    "        value_city = find_value_nextword(df, dict['filterNextWord_inSynWord_is_IF04'], ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF04']))\n",
    "        value_country = find_value_nextword(df, dict['filterNextWord_inSynWord_is_IF05'], ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF05']) )\n",
    "        value_start_building = find_date(df, dict['filterNextWord_selectSetofsynWord_IF06'], dict['filterNextWord_inSynPOS_is_IF06'], dict['filterNextWord_inSynPOS_nextwordis_IF06'],dict['filterNextWord_inSynNER_search_IF06'])\n",
    "        \n",
    "        infobox[syn_วัง['type'][0]] = value_type\n",
    "        infobox[syn_วัง['location'][0]] = value_location\n",
    "        infobox[syn_วัง['status'][0]] = value_status\n",
    "        infobox[syn_วัง['city'][0]] = value_city\n",
    "        infobox[syn_วัง['country'][0]] = value_country\n",
    "        infobox[syn_วัง['start building'][0]] = value_start_building\n",
    "\n",
    "    # อุทยานแห่งชาติ\n",
    "    elif re.search(r'เป็นอุทยานแห่งชาติ', data) or df['Word'][0] in ['อุทยานแห่งชาติ'] :\n",
    "        rule = read_googlesheet('rule_Nationalpark')\n",
    "        dict = select_rule(name_rule_nationalpark, rule = rule)\n",
    "\n",
    "\n",
    "        value_location = extract_location(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF02']), dict['filterNextWord_inSynPOS_search_IF02_1'], dict['filterNextWord_inSynNER_isBeginTag_IF02_1_1'],\n",
    "                                          dict['filterNextWord_inSynNER_isInsideTag_IF02_1_2'], dict['filterNextWord_inSynNER_search_IF02_1_3'],dict['filterNextWord_inSynWord_is_IF02_1_4'], \n",
    "                                            dict['filterNextWord_inSynNER_is_IF02_1_4'], dict['filterNextWord_inSynWord_is_IF02_1_5'], dict['filterNextWord_inSynPOS_nextis_IF02_1_5'],\n",
    "                                            dict['filterNextWord_inSynPOS_is_IF02_1_6'])\n",
    "\n",
    "        value_area = find_quantity(df,ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF01']),ast.literal_eval(dict['filterNextWord_inSynPOS_inlist_IF01']), dict['filterNextWord_inSynWord_is_IF01'],\n",
    "                                        dict['filterNextWord_inSynPOS_is_IF01'], dict['filterNextWord_inSynNER_search_IF01'])\n",
    "\n",
    "        value_government_agency = find_value_nextword_search(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF03']), dict['filterNextWord_inSynNER_search_IF03'])\n",
    "        value_establish = find_date(df, dict['filterNextWord_selectSetofsynWord_IF04'], dict['filterNextWord_inSynPOS_is_IF04'], dict['filterNextWord_inSynPOS_nextwordis_IF04'],dict['filterNextWord_inSynNER_search_IF04'])\n",
    "        value_coordinates = find_value_nextword_search(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF05']), dict['filterNextWord_inSynNER_search_IF05'])\n",
    "                                \n",
    "    \n",
    "        infobox[syn_อุทยานแห่งชาติ['location'][0]] = value_location\n",
    "        infobox[syn_อุทยานแห่งชาติ['area'][0]] = value_area\n",
    "        infobox[syn_อุทยานแห่งชาติ['government agency'][0]] = value_government_agency\n",
    "        infobox[syn_อุทยานแห่งชาติ['establish'][0]] = value_establish\n",
    "        infobox[syn_อุทยานแห่งชาติ['coordinates'][0]] = value_coordinates\n",
    "\n",
    "    # สถาบันอุดมศึกษา\n",
    "    elif re.search(r'เป็นมหาวิทยาลัย|เป็นสถาบันอุดมศึกษา|ระดับอุดมศึกษา', data) or df['Word'][0] in ['มหาวิทยาลัย', 'วิทยาลัย', 'สถาบันการอาชีวศึกษา']:\n",
    "        rule = read_googlesheet('rule_university')\n",
    "        dict = select_rule(name_rule_university, rule = rule)\n",
    "\n",
    "        value_type = find_type(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF01']),ast.literal_eval(dict['filterNextWord_inSynWord_in_IF01']),ast.literal_eval(dict['filterNextWord_inSynPOS_in_IF01']))\n",
    "\n",
    "        value_website = find_website(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF03']), dict['filterNextWord_inSynNER_search_IF03'])\n",
    "\n",
    "        value_location = extract_location(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF02']), dict['filterNextWord_inSynPOS_search_IF02_1'], dict['filterNextWord_inSynNER_isBeginTag_IF02_1_1'],\n",
    "                                          dict['filterNextWord_inSynNER_isInsideTag_IF02_1_2'], dict['filterNextWord_inSynNER_search_IF02_1_3'],dict['filterNextWord_inSynWord_is_IF02_1_4'], \n",
    "                                            dict['filterNextWord_inSynNER_is_IF02_1_4'], dict['filterNextWord_inSynWord_is_IF02_1_5'], dict['filterNextWord_inSynPOS_nextis_IF02_1_5'],\n",
    "                                            dict['filterNextWord_inSynPOS_is_IF02_1_6'])\n",
    "                                            \n",
    "        value_initials = find_value_nextword_search(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF04']), dict['filterNextWord_inSynNER_search_IF04'])\n",
    "\n",
    "        value_establish = find_date(df, dict['filterNextWord_selectSetofsynWord_IF05'], dict['filterNextWord_inSynPOS_is_IF05'], dict['filterNextWord_inSynPOS_nextwordis_IF05'],dict['filterNextWord_inSynNER_search_IF05'])\n",
    "\n",
    "        infobox[syn_สถาบันอุดมศึกษา['type'][0]] = value_type\n",
    "        infobox[syn_สถาบันอุดมศึกษา['location'][0]] = value_location\n",
    "        infobox[syn_สถาบันอุดมศึกษา['website'][0]] = value_website\n",
    "        infobox[syn_สถาบันอุดมศึกษา['initials'][0]] = value_initials\n",
    "        infobox[syn_สถาบันอุดมศึกษา['establish'][0]] = value_establish\n",
    "    \n",
    "    # โรงพยาบาล\n",
    "    elif re.search(r'เป็นสถาบันการแพทย์|เป็นโรงพยาบาล', data) or df['Word'][0] in ['โรงพยาบาล', 'ศูนย์การแพทย์'] :\n",
    "        rule = read_googlesheet('rule_hospital')\n",
    "        dict = select_rule(name_rule_hospital, rule = rule)\n",
    "\n",
    "        value_location = extract_location(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF02']), dict['filterNextWord_inSynPOS_search_IF02_1'], dict['filterNextWord_inSynNER_isBeginTag_IF02_1_1'],\n",
    "                                          dict['filterNextWord_inSynNER_isInsideTag_IF02_1_2'], dict['filterNextWord_inSynNER_search_IF02_1_3'],dict['filterNextWord_inSynWord_is_IF02_1_4'], \n",
    "                                            dict['filterNextWord_inSynNER_is_IF02_1_4'], dict['filterNextWord_inSynWord_is_IF02_1_5'], dict['filterNextWord_inSynPOS_nextis_IF02_1_5'],\n",
    "                                            dict['filterNextWord_inSynPOS_is_IF02_1_6'])\n",
    "\n",
    "        value_type = find_type(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF01']),ast.literal_eval(dict['filterNextWord_inSynWord_in_IF01']),ast.literal_eval(dict['filterNextWord_inSynPOS_in_IF01']))\n",
    "    \n",
    "        value_number_beds = find_quantity(df,ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF03']),ast.literal_eval(dict['filterNextWord_inSynPOS_inlist_IF03']), dict['filterNextWord_inSynWord_is_IF03'],\n",
    "                                        dict['filterNextWord_inSynPOS_is_IF03'], dict['filterNextWord_inSynNER_search_IF03'])\n",
    "        \n",
    "\n",
    "        value_website = find_website(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF04']), dict['filterNextWord_inSynNER_search_IF04'])\n",
    "        \n",
    "        value_affiliation = find_value_nextword_search(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF05']), dict['filterNextWord_inSynNER_search_IF05'])\n",
    "\n",
    "        \n",
    "        infobox[syn_โรงพยาบาล['type'][0]] = value_type  \n",
    "        infobox[syn_โรงพยาบาล['location'][0]] = value_location     \n",
    "        infobox[syn_โรงพยาบาล['number of beds'][0]] = value_number_beds\n",
    "        infobox[syn_โรงพยาบาล['website'][0]] = value_website\n",
    "        infobox[syn_โรงพยาบาล['affiliation'][0]] = value_affiliation\n",
    "        \n",
    "\n",
    "    # default\n",
    "    else:\n",
    "        rule = read_googlesheet('rule_default')\n",
    "        dict = select_rule(name_rule_default, rule = rule)\n",
    "\n",
    "        value_location = extract_location(df, ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF02']), dict['filterNextWord_inSynPOS_search_IF02_1'], dict['filterNextWord_inSynNER_isBeginTag_IF02_1_1'],\n",
    "                                          dict['filterNextWord_inSynNER_isInsideTag_IF02_1_2'], dict['filterNextWord_inSynNER_search_IF02_1_3'],dict['filterNextWord_inSynWord_is_IF02_1_4'], \n",
    "                                            dict['filterNextWord_inSynNER_is_IF02_1_4'], dict['filterNextWord_inSynWord_is_IF02_1_5'], dict['filterNextWord_inSynPOS_nextis_IF02_1_5'],\n",
    "                                            dict['filterNextWord_inSynPOS_is_IF02_1_6'])\n",
    "        value_type = ''\n",
    "        value_name = ''\n",
    "        value_Related_person = ''\n",
    "\n",
    "        for i in range(len(df)):\n",
    "        # name and type\n",
    "            if df['Word'][i] in ast.literal_eval(dict['filterNextWord_selectSetofsynWord_IF01']):\n",
    "                if df['Word'][i] == dict['filterNextWord_inSynWord_is_IF01']:\n",
    "                    # ชื่อ\n",
    "                    for j in range(0, i):\n",
    "                        if re.search(dict['filterNextWord_inSynPOS_search_IF01'], df['POS tags'][j]):\n",
    "                            value_name = df['Word'][j] + ' '\n",
    "                            break\n",
    "                    for j in range(i, i+2):\n",
    "                        if re.search(dict['filterNextWord_inSynPOS_search_IF01'], df['POS tags'][j]):\n",
    "                            value_type = df['Word'][j] + ' '\n",
    "                            break\n",
    "                    break\n",
    "\n",
    "            #value_Related_person\n",
    "            else :\n",
    "                if re.search(dict['filterNextWord_inSynNER_search_IF01'], df['NER'][i]):\n",
    "                    value_Related_person += df['Word'][i]\n",
    "\n",
    "        infobox[syn_default['name'][0]] = value_name\n",
    "        infobox[syn_default['type'][0]] = value_type\n",
    "        infobox[syn_default['location'][0]] = value_location\n",
    "        infobox[syn_default['Related person'][0]] = value_Related_person\n",
    "    \n",
    "    return infobox\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template_infobox_place(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
